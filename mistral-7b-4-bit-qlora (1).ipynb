{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7087178,"sourceType":"datasetVersion","datasetId":4083451}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import torch, os\n# torch.cuda.empty_cache()\n# os._exit(0)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"execution_failed":"2026-01-12T12:10:17.674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U bitsandbytes\n!pip install -U transformers\n!pip install -U peft\n!pip install -U accelerate\n!pip install -U trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:11:23.867880Z","iopub.execute_input":"2026-01-12T12:11:23.868181Z","iopub.status.idle":"2026-01-12T12:11:55.602088Z","shell.execute_reply.started":"2026-01-12T12:11:23.868156Z","shell.execute_reply":"2026-01-12T12:11:55.601396Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\nDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.49.1\nRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nCollecting transformers\n  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\nDownloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.57.1\n    Uninstalling transformers-4.57.1:\n      Successfully uninstalled transformers-4.57.1\nSuccessfully installed transformers-4.57.3\nRequirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\nCollecting peft\n  Downloading peft-0.18.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.3)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\nRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft) (4.57.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft) (4.67.1)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.11.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.6.2)\nRequirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft) (0.36.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (3.20.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.10.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (0.22.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.11.12)\nDownloading peft-0.18.1-py3-none-any.whl (556 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.0/557.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\n  Attempting uninstall: peft\n    Found existing installation: peft 0.17.1\n    Uninstalling peft-0.17.1:\n      Successfully uninstalled peft-0.17.1\nSuccessfully installed peft-0.18.1\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nCollecting accelerate\n  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.10.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\nDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.11.0\n    Uninstalling accelerate-1.11.0:\n      Successfully uninstalled accelerate-1.11.0\nSuccessfully installed accelerate-1.12.0\nCollecting trl\n  Downloading trl-0.26.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from trl) (1.12.0)\nRequirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl) (4.4.1)\nRequirement already satisfied: transformers>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from trl) (4.57.3)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (6.0.3)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.8.0+cu126)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.36.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.20.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.28.1)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.10.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (0.22.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=3.0.0->trl) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.6.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.3)\nDownloading trl-0.26.2-py3-none-any.whl (518 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: trl\nSuccessfully installed trl-0.26.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch, bitsandbytes, transformers, peft, accelerate, trl\n\nprint(\"Torch:\", torch.__version__)\nprint(\"BitsAndBytes:\", bitsandbytes.__version__)\nprint(\"Transformers:\", transformers.__version__)\nprint(\"PEFT:\", peft.__version__)\nprint(\"Accelerate:\", accelerate.__version__)\nprint(\"TRL:\", trl.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:14:24.873608Z","iopub.execute_input":"2026-01-12T12:14:24.873967Z","iopub.status.idle":"2026-01-12T12:14:54.944724Z","shell.execute_reply.started":"2026-01-12T12:14:24.873934Z","shell.execute_reply":"2026-01-12T12:14:54.943996Z"}},"outputs":[{"name":"stderr","text":"2026-01-12 12:14:42.600770: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768220082.795102      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768220082.854123      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768220083.311009      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768220083.311046      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768220083.311049      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768220083.311051      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Torch: 2.8.0+cu126\nBitsAndBytes: 0.49.1\nTransformers: 4.57.3\nPEFT: 0.18.1\nAccelerate: 1.12.0\nTRL: 0.26.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nimport os,torch\nfrom datasets import load_dataset\nfrom trl import SFTTrainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:16:28.823555Z","iopub.execute_input":"2026-01-12T12:16:28.824173Z","iopub.status.idle":"2026-01-12T12:16:28.828462Z","shell.execute_reply.started":"2026-01-12T12:16:28.824143Z","shell.execute_reply":"2026-01-12T12:16:28.827723Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"hf_token\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:06.884900Z","iopub.execute_input":"2026-01-12T12:17:06.885591Z","iopub.status.idle":"2026-01-12T12:17:07.119469Z","shell.execute_reply.started":"2026-01-12T12:17:06.885560Z","shell.execute_reply":"2026-01-12T12:17:07.118790Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"!huggingface-cli login --token $secret_value_0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:08.055180Z","iopub.execute_input":"2026-01-12T12:17:08.055714Z","iopub.status.idle":"2026-01-12T12:17:08.790676Z","shell.execute_reply.started":"2026-01-12T12:17:08.055676Z","shell.execute_reply":"2026-01-12T12:17:08.790011Z"}},"outputs":[{"name":"stdout","text":"\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\nThe token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `hf`CLI if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nThe token `llama8B` has been saved to /root/.cache/huggingface/stored_tokens\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful.\nThe current active token is: `llama8B`\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nimport os,torch\nfrom datasets import load_dataset\nfrom trl import SFTTrainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:11.065659Z","iopub.execute_input":"2026-01-12T12:17:11.066344Z","iopub.status.idle":"2026-01-12T12:17:11.070729Z","shell.execute_reply.started":"2026-01-12T12:17:11.066309Z","shell.execute_reply":"2026-01-12T12:17:11.069977Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ntrain_df=pd.read_csv(\"/kaggle/input/question-answering-training-and-testing-data/train.csv\")\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:12.031008Z","iopub.execute_input":"2026-01-12T12:17:12.031305Z","iopub.status.idle":"2026-01-12T12:17:16.247808Z","shell.execute_reply.started":"2026-01-12T12:17:12.031277Z","shell.execute_reply":"2026-01-12T12:17:16.247157Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              instruction  \\\n0                    How many seconds are in 7.8 minutes?   \n1                    How many seconds are in 7.8 minutes?   \n2                    How many seconds are in 7.8 minutes?   \n3                    How many seconds are in 7.8 minutes?   \n4                    How many seconds are in 7.8 minutes?   \n...                                                   ...   \n629465  On the Cartesian plane in which each unit is o...   \n629466  On the Cartesian plane in which each unit is o...   \n629467  Suppose we are given seven points that are equ...   \n629468  Suppose we are given seven points that are equ...   \n629469  Suppose we are given seven points that are equ...   \n\n                                                responses  \\\n0                                                      []   \n1       ['7.8 minutes is the same as 7 minutes and 0.8...   \n2       ['7.8 minutes is the same as 7 minutes and 0.8...   \n3       ['7.8 minutes is the same as 7 minutes and 0.8...   \n4       ['7.8 minutes is the same as 7 minutes and 0.8...   \n...                                                   ...   \n629465  ['I need to find the point on the rope that is...   \n629466  ['I need to find the point on the rope that is...   \n629467                                                 []   \n629468  ['I notice that the problem is asking about th...   \n629469  ['I notice that the problem is asking about th...   \n\n                                            next_response answer  \\\n0       7.8 minutes is the same as 7 minutes and 0.8 m...    NaN   \n1       Right, and since there are 60 seconds in a min...    NaN   \n2       And since there are 60 seconds in a minute, th...    NaN   \n3       So, in total, there are 420 + 48 = 468 seconds...    NaN   \n4                                                Exactly.    468   \n...                                                   ...    ...   \n629465  To find its distance from the origin, I use th...    NaN   \n629466                                                NaN     15   \n629467  I notice that the problem is asking about the ...    NaN   \n629468  So, if I want to find the possible values of $...    NaN   \n629469  I also notice that since the seven points are ...    NaN   \n\n        is_human_response  \n0                   False  \n1                   False  \n2                   False  \n3                   False  \n4                   False  \n...                   ...  \n629465              False  \n629466              False  \n629467              False  \n629468              False  \n629469              False  \n\n[629470 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>responses</th>\n      <th>next_response</th>\n      <th>answer</th>\n      <th>is_human_response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>[]</td>\n      <td>7.8 minutes is the same as 7 minutes and 0.8 m...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n      <td>Right, and since there are 60 seconds in a min...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n      <td>And since there are 60 seconds in a minute, th...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n      <td>So, in total, there are 420 + 48 = 468 seconds...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n      <td>Exactly.</td>\n      <td>468</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>629465</th>\n      <td>On the Cartesian plane in which each unit is o...</td>\n      <td>['I need to find the point on the rope that is...</td>\n      <td>To find its distance from the origin, I use th...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>629466</th>\n      <td>On the Cartesian plane in which each unit is o...</td>\n      <td>['I need to find the point on the rope that is...</td>\n      <td>NaN</td>\n      <td>15</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>629467</th>\n      <td>Suppose we are given seven points that are equ...</td>\n      <td>[]</td>\n      <td>I notice that the problem is asking about the ...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>629468</th>\n      <td>Suppose we are given seven points that are equ...</td>\n      <td>['I notice that the problem is asking about th...</td>\n      <td>So, if I want to find the possible values of $...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>629469</th>\n      <td>Suppose we are given seven points that are equ...</td>\n      <td>['I notice that the problem is asking about th...</td>\n      <td>I also notice that since the seven points are ...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>629470 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"train_df.drop_duplicates(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:16.249045Z","iopub.execute_input":"2026-01-12T12:17:16.249287Z","iopub.status.idle":"2026-01-12T12:17:17.399998Z","shell.execute_reply.started":"2026-01-12T12:17:16.249265Z","shell.execute_reply":"2026-01-12T12:17:17.398972Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"train_df.drop(columns=[\"next_response\",\"answer\",\"is_human_response\"], inplace=True)\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:17.400993Z","iopub.execute_input":"2026-01-12T12:17:17.401372Z","iopub.status.idle":"2026-01-12T12:17:17.446646Z","shell.execute_reply.started":"2026-01-12T12:17:17.401344Z","shell.execute_reply":"2026-01-12T12:17:17.446067Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                                              instruction  \\\n0                    How many seconds are in 7.8 minutes?   \n1                    How many seconds are in 7.8 minutes?   \n2                    How many seconds are in 7.8 minutes?   \n3                    How many seconds are in 7.8 minutes?   \n4                    How many seconds are in 7.8 minutes?   \n...                                                   ...   \n629465  On the Cartesian plane in which each unit is o...   \n629466  On the Cartesian plane in which each unit is o...   \n629467  Suppose we are given seven points that are equ...   \n629468  Suppose we are given seven points that are equ...   \n629469  Suppose we are given seven points that are equ...   \n\n                                                responses  \n0                                                      []  \n1       ['7.8 minutes is the same as 7 minutes and 0.8...  \n2       ['7.8 minutes is the same as 7 minutes and 0.8...  \n3       ['7.8 minutes is the same as 7 minutes and 0.8...  \n4       ['7.8 minutes is the same as 7 minutes and 0.8...  \n...                                                   ...  \n629465  ['I need to find the point on the rope that is...  \n629466  ['I need to find the point on the rope that is...  \n629467                                                 []  \n629468  ['I notice that the problem is asking about th...  \n629469  ['I notice that the problem is asking about th...  \n\n[464733 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>responses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>629465</th>\n      <td>On the Cartesian plane in which each unit is o...</td>\n      <td>['I need to find the point on the rope that is...</td>\n    </tr>\n    <tr>\n      <th>629466</th>\n      <td>On the Cartesian plane in which each unit is o...</td>\n      <td>['I need to find the point on the rope that is...</td>\n    </tr>\n    <tr>\n      <th>629467</th>\n      <td>Suppose we are given seven points that are equ...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>629468</th>\n      <td>Suppose we are given seven points that are equ...</td>\n      <td>['I notice that the problem is asking about th...</td>\n    </tr>\n    <tr>\n      <th>629469</th>\n      <td>Suppose we are given seven points that are equ...</td>\n      <td>['I notice that the problem is asking about th...</td>\n    </tr>\n  </tbody>\n</table>\n<p>464733 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:17.447974Z","iopub.execute_input":"2026-01-12T12:17:17.448221Z","iopub.status.idle":"2026-01-12T12:17:17.521785Z","shell.execute_reply.started":"2026-01-12T12:17:17.448198Z","shell.execute_reply":"2026-01-12T12:17:17.521221Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"instruction    0\nresponses      0\ndtype: int64"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"train_df = train_df[train_df[\"responses\"] != \"[]\"]\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:17.522782Z","iopub.execute_input":"2026-01-12T12:17:17.523082Z","iopub.status.idle":"2026-01-12T12:17:17.618557Z","shell.execute_reply.started":"2026-01-12T12:17:17.523049Z","shell.execute_reply":"2026-01-12T12:17:17.617960Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                                              instruction  \\\n1                    How many seconds are in 7.8 minutes?   \n2                    How many seconds are in 7.8 minutes?   \n3                    How many seconds are in 7.8 minutes?   \n4                    How many seconds are in 7.8 minutes?   \n6       How many positive two-digit integers leave a r...   \n...                                                   ...   \n629464  On the Cartesian plane in which each unit is o...   \n629465  On the Cartesian plane in which each unit is o...   \n629466  On the Cartesian plane in which each unit is o...   \n629468  Suppose we are given seven points that are equ...   \n629469  Suppose we are given seven points that are equ...   \n\n                                                responses  \n1       ['7.8 minutes is the same as 7 minutes and 0.8...  \n2       ['7.8 minutes is the same as 7 minutes and 0.8...  \n3       ['7.8 minutes is the same as 7 minutes and 0.8...  \n4       ['7.8 minutes is the same as 7 minutes and 0.8...  \n6       [\"So if a number leaves a remainder of 2 when ...  \n...                                                   ...  \n629464  ['I need to find the point on the rope that is...  \n629465  ['I need to find the point on the rope that is...  \n629466  ['I need to find the point on the rope that is...  \n629468  ['I notice that the problem is asking about th...  \n629469  ['I notice that the problem is asking about th...  \n\n[398009 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>responses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>How many positive two-digit integers leave a r...</td>\n      <td>[\"So if a number leaves a remainder of 2 when ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>629464</th>\n      <td>On the Cartesian plane in which each unit is o...</td>\n      <td>['I need to find the point on the rope that is...</td>\n    </tr>\n    <tr>\n      <th>629465</th>\n      <td>On the Cartesian plane in which each unit is o...</td>\n      <td>['I need to find the point on the rope that is...</td>\n    </tr>\n    <tr>\n      <th>629466</th>\n      <td>On the Cartesian plane in which each unit is o...</td>\n      <td>['I need to find the point on the rope that is...</td>\n    </tr>\n    <tr>\n      <th>629468</th>\n      <td>Suppose we are given seven points that are equ...</td>\n      <td>['I notice that the problem is asking about th...</td>\n    </tr>\n    <tr>\n      <th>629469</th>\n      <td>Suppose we are given seven points that are equ...</td>\n      <td>['I notice that the problem is asking about th...</td>\n    </tr>\n  </tbody>\n</table>\n<p>398009 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"train_df.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:17.619531Z","iopub.execute_input":"2026-01-12T12:17:17.619835Z","iopub.status.idle":"2026-01-12T12:17:18.362462Z","shell.execute_reply.started":"2026-01-12T12:17:17.619802Z","shell.execute_reply":"2026-01-12T12:17:18.361839Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"np.int64(1894)"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"train_df.drop_duplicates(inplace=True)\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:18.363380Z","iopub.execute_input":"2026-01-12T12:17:18.363705Z","iopub.status.idle":"2026-01-12T12:17:19.138236Z","shell.execute_reply.started":"2026-01-12T12:17:18.363662Z","shell.execute_reply":"2026-01-12T12:17:19.137388Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/1811325075.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df.drop_duplicates(inplace=True)\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                                              instruction  \\\n1                    How many seconds are in 7.8 minutes?   \n2                    How many seconds are in 7.8 minutes?   \n3                    How many seconds are in 7.8 minutes?   \n4                    How many seconds are in 7.8 minutes?   \n6       How many positive two-digit integers leave a r...   \n...                                                   ...   \n629464  On the Cartesian plane in which each unit is o...   \n629465  On the Cartesian plane in which each unit is o...   \n629466  On the Cartesian plane in which each unit is o...   \n629468  Suppose we are given seven points that are equ...   \n629469  Suppose we are given seven points that are equ...   \n\n                                                responses  \n1       ['7.8 minutes is the same as 7 minutes and 0.8...  \n2       ['7.8 minutes is the same as 7 minutes and 0.8...  \n3       ['7.8 minutes is the same as 7 minutes and 0.8...  \n4       ['7.8 minutes is the same as 7 minutes and 0.8...  \n6       [\"So if a number leaves a remainder of 2 when ...  \n...                                                   ...  \n629464  ['I need to find the point on the rope that is...  \n629465  ['I need to find the point on the rope that is...  \n629466  ['I need to find the point on the rope that is...  \n629468  ['I notice that the problem is asking about th...  \n629469  ['I notice that the problem is asking about th...  \n\n[396115 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>responses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How many seconds are in 7.8 minutes?</td>\n      <td>['7.8 minutes is the same as 7 minutes and 0.8...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>How many positive two-digit integers leave a r...</td>\n      <td>[\"So if a number leaves a remainder of 2 when ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>629464</th>\n      <td>On the Cartesian plane in which each unit is o...</td>\n      <td>['I need to find the point on the rope that is...</td>\n    </tr>\n    <tr>\n      <th>629465</th>\n      <td>On the Cartesian plane in which each unit is o...</td>\n      <td>['I need to find the point on the rope that is...</td>\n    </tr>\n    <tr>\n      <th>629466</th>\n      <td>On the Cartesian plane in which each unit is o...</td>\n      <td>['I need to find the point on the rope that is...</td>\n    </tr>\n    <tr>\n      <th>629468</th>\n      <td>Suppose we are given seven points that are equ...</td>\n      <td>['I notice that the problem is asking about th...</td>\n    </tr>\n    <tr>\n      <th>629469</th>\n      <td>Suppose we are given seven points that are equ...</td>\n      <td>['I notice that the problem is asking about th...</td>\n    </tr>\n  </tbody>\n</table>\n<p>396115 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"test_df=pd.read_csv(\"/kaggle/input/question-answering-training-and-testing-data/test.csv\")\ntest_df.drop(columns=[\"next_response\",\"answer\",\"is_human_response\"], inplace=True)\n\ntest_df = test_df[test_df[\"responses\"] != \"[]\"]\ntest_df.drop_duplicates(inplace=True)\ntest_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:19.139292Z","iopub.execute_input":"2026-01-12T12:17:19.139642Z","iopub.status.idle":"2026-01-12T12:17:19.307241Z","shell.execute_reply.started":"2026-01-12T12:17:19.139605Z","shell.execute_reply":"2026-01-12T12:17:19.306474Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"                                             instruction  \\\n1      Three pencils and a jumbo eraser cost $\\$1.24$...   \n2      Three pencils and a jumbo eraser cost $\\$1.24$...   \n3      Three pencils and a jumbo eraser cost $\\$1.24$...   \n4      Three pencils and a jumbo eraser cost $\\$1.24$...   \n5      Three pencils and a jumbo eraser cost $\\$1.24$...   \n...                                                  ...   \n19222             Simplify $\\frac{(10r^3)(4r^6)}{8r^4}$.   \n19224  Find the midpoint of the line segment between ...   \n19225  Find the midpoint of the line segment between ...   \n19226  Find the midpoint of the line segment between ...   \n19227  Find the midpoint of the line segment between ...   \n\n                                               responses  \n1      [\"Let's call the price of a pencil p and the p...  \n2      [\"Let's call the price of a pencil p and the p...  \n3      [\"Let's call the price of a pencil p and the p...  \n4      [\"Let's call the price of a pencil p and the p...  \n5      [\"Let's call the price of a pencil p and the p...  \n...                                                  ...  \n19222  ['To simplify a fraction involving powers of t...  \n19224  ['I know that the midpoint of a line segment i...  \n19225  ['I know that the midpoint of a line segment i...  \n19226  ['I know that the midpoint of a line segment i...  \n19227  ['I know that the midpoint of a line segment i...  \n\n[16120 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>responses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Three pencils and a jumbo eraser cost $\\$1.24$...</td>\n      <td>[\"Let's call the price of a pencil p and the p...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Three pencils and a jumbo eraser cost $\\$1.24$...</td>\n      <td>[\"Let's call the price of a pencil p and the p...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Three pencils and a jumbo eraser cost $\\$1.24$...</td>\n      <td>[\"Let's call the price of a pencil p and the p...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Three pencils and a jumbo eraser cost $\\$1.24$...</td>\n      <td>[\"Let's call the price of a pencil p and the p...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Three pencils and a jumbo eraser cost $\\$1.24$...</td>\n      <td>[\"Let's call the price of a pencil p and the p...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19222</th>\n      <td>Simplify $\\frac{(10r^3)(4r^6)}{8r^4}$.</td>\n      <td>['To simplify a fraction involving powers of t...</td>\n    </tr>\n    <tr>\n      <th>19224</th>\n      <td>Find the midpoint of the line segment between ...</td>\n      <td>['I know that the midpoint of a line segment i...</td>\n    </tr>\n    <tr>\n      <th>19225</th>\n      <td>Find the midpoint of the line segment between ...</td>\n      <td>['I know that the midpoint of a line segment i...</td>\n    </tr>\n    <tr>\n      <th>19226</th>\n      <td>Find the midpoint of the line segment between ...</td>\n      <td>['I know that the midpoint of a line segment i...</td>\n    </tr>\n    <tr>\n      <th>19227</th>\n      <td>Find the midpoint of the line segment between ...</td>\n      <td>['I know that the midpoint of a line segment i...</td>\n    </tr>\n  </tbody>\n</table>\n<p>16120 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"test_df[\"instruction\"][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T13:57:59.990394Z","iopub.execute_input":"2026-01-12T13:57:59.990839Z","iopub.status.idle":"2026-01-12T13:57:59.999381Z","shell.execute_reply.started":"2026-01-12T13:57:59.990796Z","shell.execute_reply":"2026-01-12T13:57:59.998483Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"'Three pencils and a jumbo eraser cost $\\\\$1.24$. Five pencils and a jumbo eraser cost $\\\\$1.82$. No prices include tax. In cents, what is the cost of a pencil?'"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n# secret_label = \"hf_token\"\n# hf_token = user_secrets.get_secret(secret_label)\n# print(\"Secret fetched successfully\")\n# print(hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:16:59.252504Z","iopub.execute_input":"2026-01-12T12:16:59.253106Z","iopub.status.idle":"2026-01-12T12:16:59.256421Z","shell.execute_reply.started":"2026-01-12T12:16:59.253079Z","shell.execute_reply":"2026-01-12T12:16:59.255749Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# from huggingface_hub import HfApi, login\n\n# login(token=hf_token)\n# api = HfApi()\n# user_info = api.whoami()\n# print(user_info)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:02.919156Z","iopub.execute_input":"2026-01-12T12:17:02.919723Z","iopub.status.idle":"2026-01-12T12:17:02.922976Z","shell.execute_reply.started":"2026-01-12T12:17:02.919685Z","shell.execute_reply":"2026-01-12T12:17:02.922285Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def format_prompt(row):\n    return f\"\"\"### Instruction:\n{row['instruction']}\n\n### Response:\n{row['responses']}\"\"\"\n\ntrain_df[\"text\"] = train_df.apply(format_prompt, axis=1)\ntest_df[\"text\"] = test_df.apply(format_prompt, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:22.140431Z","iopub.execute_input":"2026-01-12T12:17:22.140757Z","iopub.status.idle":"2026-01-12T12:17:24.650929Z","shell.execute_reply.started":"2026-01-12T12:17:22.140730Z","shell.execute_reply":"2026-01-12T12:17:24.650223Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/1244945955.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df[\"text\"] = train_df.apply(format_prompt, axis=1)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"train_df[\"text\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:27.429319Z","iopub.execute_input":"2026-01-12T12:17:27.429632Z","iopub.status.idle":"2026-01-12T12:17:27.436958Z","shell.execute_reply.started":"2026-01-12T12:17:27.429606Z","shell.execute_reply":"2026-01-12T12:17:27.436267Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"1         ### Instruction:\\nHow many seconds are in 7.8 ...\n2         ### Instruction:\\nHow many seconds are in 7.8 ...\n3         ### Instruction:\\nHow many seconds are in 7.8 ...\n4         ### Instruction:\\nHow many seconds are in 7.8 ...\n6         ### Instruction:\\nHow many positive two-digit ...\n                                ...                        \n629464    ### Instruction:\\nOn the Cartesian plane in wh...\n629465    ### Instruction:\\nOn the Cartesian plane in wh...\n629466    ### Instruction:\\nOn the Cartesian plane in wh...\n629468    ### Instruction:\\nSuppose we are given seven p...\n629469    ### Instruction:\\nSuppose we are given seven p...\nName: text, Length: 396115, dtype: object"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"from datasets import Dataset\n\ntrain_dataset = Dataset.from_pandas(train_df[[\"text\"]])\ntest_dataset= test_dataset = Dataset.from_pandas(test_df[[\"text\"]])\n\ntrain_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:30.223799Z","iopub.execute_input":"2026-01-12T12:17:30.224102Z","iopub.status.idle":"2026-01-12T12:17:32.675188Z","shell.execute_reply.started":"2026-01-12T12:17:30.224074Z","shell.execute_reply":"2026-01-12T12:17:32.674573Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', '__index_level_0__'],\n    num_rows: 396115\n})"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"test_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:32.676537Z","iopub.execute_input":"2026-01-12T12:17:32.676848Z","iopub.status.idle":"2026-01-12T12:17:32.681900Z","shell.execute_reply.started":"2026-01-12T12:17:32.676826Z","shell.execute_reply":"2026-01-12T12:17:32.681227Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', '__index_level_0__'],\n    num_rows: 16120\n})"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"train_dataset[\"text\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:34.206204Z","iopub.execute_input":"2026-01-12T12:17:34.206813Z","iopub.status.idle":"2026-01-12T12:17:34.216547Z","shell.execute_reply.started":"2026-01-12T12:17:34.206781Z","shell.execute_reply":"2026-01-12T12:17:34.215860Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"Column([\"### Instruction:\\nHow many seconds are in 7.8 minutes?\\n\\n### Response:\\n['7.8 minutes is the same as 7 minutes and 0.8 minutes.']\", \"### Instruction:\\nHow many seconds are in 7.8 minutes?\\n\\n### Response:\\n['7.8 minutes is the same as 7 minutes and 0.8 minutes.'\\n 'Right, and since there are 60 seconds in a minute, then there are 60 * 7 = 420 seconds in 7 minutes.']\", \"### Instruction:\\nHow many seconds are in 7.8 minutes?\\n\\n### Response:\\n['7.8 minutes is the same as 7 minutes and 0.8 minutes.'\\n 'Right, and since there are 60 seconds in a minute, then there are 60 * 7 = 420 seconds in 7 minutes.'\\n 'And since there are 60 seconds in a minute, then there are 60 * 0.8 = 48 seconds in 0.8 minutes.']\", \"### Instruction:\\nHow many seconds are in 7.8 minutes?\\n\\n### Response:\\n['7.8 minutes is the same as 7 minutes and 0.8 minutes.'\\n 'Right, and since there are 60 seconds in a minute, then there are 60 * 7 = 420 seconds in 7 minutes.'\\n 'And since there are 60 seconds in a minute, then there are 60 * 0.8 = 48 seconds in 0.8 minutes.'\\n 'So, in total, there are 420 + 48 = 468 seconds in 7.8 minutes.']\", '### Instruction:\\nHow many positive two-digit integers leave a remainder of 2 when divided by 8?\\n\\n### Response:\\n[\"So if a number leaves a remainder of 2 when divided by 8, it\\'s of the form 8n+2.\"]'])"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"train_dataset = train_dataset.remove_columns([\"__index_level_0__\"])\ntest_dataset = test_dataset.remove_columns([\"__index_level_0__\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:34.612236Z","iopub.execute_input":"2026-01-12T12:17:34.612968Z","iopub.status.idle":"2026-01-12T12:17:34.619612Z","shell.execute_reply.started":"2026-01-12T12:17:34.612930Z","shell.execute_reply":"2026-01-12T12:17:34.618843Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:35.106701Z","iopub.execute_input":"2026-01-12T12:17:35.107157Z","iopub.status.idle":"2026-01-12T12:17:35.111849Z","shell.execute_reply.started":"2026-01-12T12:17:35.107131Z","shell.execute_reply":"2026-01-12T12:17:35.111247Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 396115\n})"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"test_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:35.610355Z","iopub.execute_input":"2026-01-12T12:17:35.610716Z","iopub.status.idle":"2026-01-12T12:17:35.615137Z","shell.execute_reply.started":"2026-01-12T12:17:35.610684Z","shell.execute_reply":"2026-01-12T12:17:35.614622Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 16120\n})"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"test_dataset[\"text\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:36.886297Z","iopub.execute_input":"2026-01-12T12:17:36.887037Z","iopub.status.idle":"2026-01-12T12:17:36.892109Z","shell.execute_reply.started":"2026-01-12T12:17:36.887005Z","shell.execute_reply":"2026-01-12T12:17:36.891473Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"Column(['### Instruction:\\nThree pencils and a jumbo eraser cost $\\\\$1.24$. Five pencils and a jumbo eraser cost $\\\\$1.82$. No prices include tax. In cents, what is the cost of a pencil?\\n\\n### Response:\\n[\"Let\\'s call the price of a pencil p and the price of a jumbo eraser e. Then we can write two equations.\"]', '### Instruction:\\nThree pencils and a jumbo eraser cost $\\\\$1.24$. Five pencils and a jumbo eraser cost $\\\\$1.82$. No prices include tax. In cents, what is the cost of a pencil?\\n\\n### Response:\\n[\"Let\\'s call the price of a pencil p and the price of a jumbo eraser e. Then we can write two equations.\"\\n \\'We have $3p+e=1.24$ and $5p+e=1.82$.\\']', '### Instruction:\\nThree pencils and a jumbo eraser cost $\\\\$1.24$. Five pencils and a jumbo eraser cost $\\\\$1.82$. No prices include tax. In cents, what is the cost of a pencil?\\n\\n### Response:\\n[\"Let\\'s call the price of a pencil p and the price of a jumbo eraser e. Then we can write two equations.\"\\n \\'We have $3p+e=1.24$ and $5p+e=1.82$.\\'\\n \"To solve this system, let\\'s subtract the first equation from the second equation. This will eliminate e.\"]', '### Instruction:\\nThree pencils and a jumbo eraser cost $\\\\$1.24$. Five pencils and a jumbo eraser cost $\\\\$1.82$. No prices include tax. In cents, what is the cost of a pencil?\\n\\n### Response:\\n[\"Let\\'s call the price of a pencil p and the price of a jumbo eraser e. Then we can write two equations.\"\\n \\'We have $3p+e=1.24$ and $5p+e=1.82$.\\'\\n \"To solve this system, let\\'s subtract the first equation from the second equation. This will eliminate e.\"\\n \\'$5p+e-3p-e=1.82-1.24$.\\']', '### Instruction:\\nThree pencils and a jumbo eraser cost $\\\\$1.24$. Five pencils and a jumbo eraser cost $\\\\$1.82$. No prices include tax. In cents, what is the cost of a pencil?\\n\\n### Response:\\n[\"Let\\'s call the price of a pencil p and the price of a jumbo eraser e. Then we can write two equations.\"\\n \\'We have $3p+e=1.24$ and $5p+e=1.82$.\\'\\n \"To solve this system, let\\'s subtract the first equation from the second equation. This will eliminate e.\"\\n \\'$5p+e-3p-e=1.82-1.24$.\\' \\'This simplifies to $2p=0.58$. So $p=0.29$.\\']'])"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig\n)\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:17:37.501843Z","iopub.execute_input":"2026-01-12T12:17:37.502446Z","iopub.status.idle":"2026-01-12T12:17:37.505997Z","shell.execute_reply.started":"2026-01-12T12:17:37.502386Z","shell.execute_reply":"2026-01-12T12:17:37.505314Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom transformers import BitsAndBytesConfig\nimport torch\n\nbase_model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n\nbnb_config = BitsAndBytesConfig(  \n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    # bnb_4bit_compute_dtype=torch.float16, \n    bnb_4bit_use_double_quant=False,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    torch_dtype=torch.bfloat16,\n    # bnb_4bit_compute_dtype=torch.float16, \n    device_map=\"auto\",\n    trust_remote_code=True,\n)\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\nmodel.gradient_checkpointing_enable()\n\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.padding_side = 'right'\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_eos_token = True\ntokenizer.add_bos_token, tokenizer.add_eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:19:11.172205Z","iopub.execute_input":"2026-01-12T12:19:11.172542Z","iopub.status.idle":"2026-01-12T12:22:03.646118Z","shell.execute_reply.started":"2026-01-12T12:19:11.172513Z","shell.execute_reply":"2026-01-12T12:22:03.645360Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"749fe6b405d44ef0b930d466ee884842"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed518ceae4ac49828467c66aeb10d81d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"935abe36eee843d784a560fa77c79257"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e51e233a5d14f8ab8631c9acbf70e86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"156b5ed315924b72941f14a03a27d6f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df2237426f7b47508ecbbc5795b34179"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a36e150ec18945c19256e898d369c237"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be2a422a473f46eaa598c5284fad790f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7d565ee06564b43a9e1834ae60cf628"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1858019491d1403194da5674b64f2613"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f261a3bf85e647dfa2c2c00a1d7498da"}},"metadata":{}},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"(True, True)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\nmodel = prepare_model_for_kbit_training(model)\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:22:48.654371Z","iopub.execute_input":"2026-01-12T12:22:48.655019Z","iopub.status.idle":"2026-01-12T12:22:49.650365Z","shell.execute_reply.started":"2026-01-12T12:22:48.654989Z","shell.execute_reply":"2026-01-12T12:22:49.649612Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:285: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_steps= 25,\n    logging_steps= 25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n    report_to=\"none\",\n    # eval_strategy=\"steps\",  \n    # eval_steps= 25\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:55:07.245180Z","iopub.execute_input":"2026-01-12T12:55:07.245523Z","iopub.status.idle":"2026-01-12T12:55:07.273641Z","shell.execute_reply.started":"2026-01-12T12:55:07.245495Z","shell.execute_reply":"2026-01-12T12:55:07.273062Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    # eval_dataset=test_dataset,\n    peft_config=peft_config,\n    args=training_arguments,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T12:55:08.123141Z","iopub.execute_input":"2026-01-12T12:55:08.123878Z","iopub.status.idle":"2026-01-12T13:52:10.171297Z","shell.execute_reply.started":"2026-01-12T12:55:08.123830Z","shell.execute_reply":"2026-01-12T13:52:10.170237Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/bnb.py:397: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:285: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Adding EOS to train dataset:   0%|          | 0/396115 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55c864439a6042f9915ec129c2399ee1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/396115 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc67810d0004beeb2640930c853987e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/396115 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8dce6b463fa466ca507c0d0fa610b13"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='296' max='99029' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  296/99029 51:09 < 286:22:24, 0.10 it/s, Epoch 0.00/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>0.703800</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.884100</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.640000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.840000</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.594600</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.776800</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.609400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.769100</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.588400</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.756300</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>0.574000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2843536782.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2672\u001b[0m                     )\n\u001b[1;32m   2673\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_activation_offload_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4069\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale_wrt_gas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4071\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":61},{"cell_type":"code","source":"model.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T13:52:24.835341Z","iopub.execute_input":"2026-01-12T13:52:24.835634Z","iopub.status.idle":"2026-01-12T13:52:24.854837Z","shell.execute_reply.started":"2026-01-12T13:52:24.835611Z","shell.execute_reply":"2026-01-12T13:52:24.854166Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): PeftModelForCausalLM(\n      (base_model): LoraModel(\n        (model): MistralForCausalLM(\n          (model): MistralModel(\n            (embed_tokens): Embedding(32768, 4096)\n            (layers): ModuleList(\n              (0-31): 32 x MistralDecoderLayer(\n                (self_attn): MistralAttention(\n                  (q_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=64, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=64, out_features=4096, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=64, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=64, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (v_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=64, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=64, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=64, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=64, out_features=4096, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                )\n                (mlp): MistralMLP(\n                  (gate_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=64, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=64, out_features=14336, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                  (act_fn): SiLUActivation()\n                )\n                (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n                (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n              )\n            )\n            (norm): MistralRMSNorm((4096,), eps=1e-05)\n            (rotary_emb): MistralRotaryEmbedding()\n          )\n          (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"test_df[\"instruction\"][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T13:58:13.126939Z","iopub.execute_input":"2026-01-12T13:58:13.127230Z","iopub.status.idle":"2026-01-12T13:58:13.131989Z","shell.execute_reply.started":"2026-01-12T13:58:13.127204Z","shell.execute_reply":"2026-01-12T13:58:13.131428Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"'Three pencils and a jumbo eraser cost $\\\\$1.24$. Five pencils and a jumbo eraser cost $\\\\$1.82$. No prices include tax. In cents, what is the cost of a pencil?'"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"prompt = \"Three pencils and a jumbo eraser cost $\\\\$1.24$. Five pencils and a jumbo eraser cost $\\\\$1.82$. No prices include tax. In cents, what is the cost of a pencil?\"\n\ninputs = tokenizer(\n    prompt,\n    return_tensors=\"pt\",\n    padding=False,\n    truncation=True,\n).to(model.device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T13:55:17.402097Z","iopub.execute_input":"2026-01-12T13:55:17.402823Z","iopub.status.idle":"2026-01-12T13:55:17.407073Z","shell.execute_reply.started":"2026-01-12T13:55:17.402794Z","shell.execute_reply":"2026-01-12T13:55:17.406483Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"with torch.no_grad():\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=200,\n        do_sample=True,\n        temperature=0.7,\n        top_p=0.9,\n        repetition_penalty=1.1,\n        eos_token_id=tokenizer.eos_token_id,\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T13:55:20.144773Z","iopub.execute_input":"2026-01-12T13:55:20.145370Z","iopub.status.idle":"2026-01-12T13:55:40.409141Z","shell.execute_reply.started":"2026-01-12T13:55:20.145344Z","shell.execute_reply":"2026-01-12T13:55:40.408482Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"response = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T13:55:40.410319Z","iopub.execute_input":"2026-01-12T13:55:40.410700Z","iopub.status.idle":"2026-01-12T13:55:40.415422Z","shell.execute_reply.started":"2026-01-12T13:55:40.410649Z","shell.execute_reply":"2026-01-12T13:55:40.414644Z"}},"outputs":[{"name":"stdout","text":"Three pencils and a jumbo eraser cost $\\$1.24$. Five pencils and a jumbo eraser cost $\\$1.82$. No prices include tax. In cents, what is the cost of a pencil?### I'm having trouble understanding how to use the given information to find the price of a pencil in cents.\n\nI can see that three pencils and a jumbo eraser cost $1.24$, so I could divide by 3 to get the cost per pencil. However, that would give me an answer in dollars, not cents. To convert to cents, I need to multiply by 100. But then I have a fraction, which I don't want.\n\nSo maybe I should try another approach: I can subtract the cost of the jumbo eraser from each total cost, since it's the same in both cases. Then I can divide by 2 to get the cost per pencil. This would also give me an answer in dollars, but I can convert to cents by multiplying by 100 again.\n\nWhat do you think? Which approach is better or more accurate\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"prompt= \"Three pencils and a jumbo eraser cost $\\\\$1.24$. Five pencils and a jumbo eraser cost $\\\\$1.82$. No prices include tax. In cents, what is the cost of a pencil?\"\ninputs = tokenizer(\n    prompt,\n    return_tensors=\"pt\",\n    padding=False,\n    truncation=True,\n).to(model.device)\n\nwith torch.no_grad():\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=256,\n        do_sample=True,\n        temperature=0.2,\n        top_p=0.8,\n        repetition_penalty=1.2,\n        eos_token_id=tokenizer.eos_token_id,\n    )\n\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T14:10:53.443287Z","iopub.execute_input":"2026-01-12T14:10:53.444221Z","iopub.status.idle":"2026-01-12T14:11:10.211080Z","shell.execute_reply.started":"2026-01-12T14:10:53.444186Z","shell.execute_reply":"2026-01-12T14:11:10.210351Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Three pencils and a jumbo eraser cost $\\$1.24$. Five pencils and a jumbo eraser cost $\\$1.82$. No prices include tax. In cents, what is the cost of a pencil? ### I need to find out how much one pencil costs in cents.\nLet's call that x. Then we can set up two equations based on the given information:\n\nx + 3(x) = 124 for three pencils and an eraser\n5x + 3(x) = 182 for five pencils and an eraser\n\nTo solve these equations, we can subtract the first equation from the second one: (5x - x) + 0 = 68. This simplifies to 4x = 68. Dividing both sides by 4 gives us x = 17. So each pencil costs $1.70 in dollars or 170 cents.\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"prompt= \"\"\"Steve says to Jon, \"I am thinking of a polynomial whose roots are all positive integers. The polynomial has the form $P(x) = 2x^3-2ax^2+(a^2-81)x-c$ for some positive integers $a$ and $c$. Can you tell me the values of $a$ and $c$?\"\\n\\nAfter some calculations, Jon says, \"There is more than one such polynomial.\"\\n\\nSteve says, \"You\\'re right. Here is the value of $a$.\" He writes down a positive integer and asks, \"Can you tell me the value of $c$?\"\\n\\nJon says, \"There are still two possible values of $c$.\"\\n\\nFind the sum of the two possible values of $c$.\"\"\"\n\ninputs = tokenizer(\n    prompt,\n    return_tensors=\"pt\",\n    padding=False,\n    truncation=True,\n).to(model.device)\n\nwith torch.no_grad():\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=256,\n        do_sample=True,\n        temperature=0.3,\n        top_p=0.7,\n        repetition_penalty=1.1,\n        eos_token_id=tokenizer.eos_token_id,\n    )\n\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T14:05:41.774226Z","iopub.execute_input":"2026-01-12T14:05:41.774822Z","iopub.status.idle":"2026-01-12T14:06:08.112628Z","shell.execute_reply.started":"2026-01-12T14:05:41.774793Z","shell.execute_reply":"2026-01-12T14:06:08.111786Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Steve says to Jon, \"I am thinking of a polynomial whose roots are all positive integers. The polynomial has the form $P(x) = 2x^3-2ax^2+(a^2-81)x-c$ for some positive integers $a$ and $c$. Can you tell me the values of $a$ and $c$?\"\n\nAfter some calculations, Jon says, \"There is more than one such polynomial.\"\n\nSteve says, \"You're right. Here is the value of $a$.\" He writes down a positive integer and asks, \"Can you tell me the value of $c$?\"\n\nJon says, \"There are still two possible values of $c$.\"\n\nFind the sum of the two possible values of $c$. How many positive integers $a$ satisfy the given condition?\n\nTo find the number of positive integers $a$ that make the polynomial have all positive integer roots, I need to use the rational root theorem, which says that any rational root of the polynomial must be of the form $\\\\frac{p}{q}$, where $p$ is a factor of the constant term and $q$ is a factor of the leading coefficient. Since the polynomial has no rational roots, it means that $p$ must be a positive integer and $q$ must be a positive integer as well.\n\nThe leading coefficient of the polynomial is $2$, so $q$ must be a factor of $2$. This means that $q$ can only be $1$ or $2$. If $q=1$, then $p$ must be a factor of $-c$, since the constant term is $-c$. But $c$ is a positive integer, so there are no negative factors of $c$. Therefore, if $q=1$, there are no rational roots at all, and the polynomial must have all positive integer roots.\n\nIf $q=2$, then $p$ must be a factor of $4c$, since the constant\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"prompt = \"How many positive two-digit integers leave a remainder of 2 when divided by 8?\"\n\ninputs = tokenizer(\n    prompt,\n    return_tensors=\"pt\",\n    padding=False,\n    truncation=True,\n).to(model.device)\n\nwith torch.no_grad():\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=256,\n        do_sample=True,\n        temperature=0.3,\n        top_p=0.8,\n        repetition_penalty=1.1,\n        eos_token_id=tokenizer.eos_token_id,\n    )\n\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T14:15:10.515023Z","iopub.execute_input":"2026-01-12T14:15:10.515313Z","iopub.status.idle":"2026-01-12T14:15:36.370601Z","shell.execute_reply.started":"2026-01-12T14:15:10.515286Z","shell.execute_reply":"2026-01-12T14:15:36.369882Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"How many positive two-digit integers leave a remainder of 2 when divided by 8? ### I notice that the first two digits of a number must be even, since 2 is the remainder.\nWhat are some examples of such numbers?\n\nI also know that the second digit cannot be 0, because then the number would not have a remainder of 2 when divided by 8.\nSo what are some other possibilities for the second digit?\n\nI think it could be 2, 4, or 6, but I'm not sure about the others.\nHow can I check if they work?\n\nTo check if a number has a remainder of 2 when divided by 8, I need to subtract 8 from it and see if the result is even.\nIf it is, then the original number had a remainder of 2.\n\nFor example, if I have 12, which is even, then 12 - 8 = 4, which is also even, so 12 has a remainder of 2 when divided by 8.\nSimilarly, if I have 32, which is even, then 32 - 8 = 24, which is even, so 32 has a remainder of 2 when divided by\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}